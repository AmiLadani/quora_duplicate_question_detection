{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation,GlobalAveragePooling1D,Lambda,Bidirectional\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras import backend as B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_data = np.load(open('q1_train.npy', 'rb'))\n",
    "q2_data = np.load(open('q2_train.npy', 'rb'))\n",
    "\n",
    "labels = np.load(open('label_train.npy', 'rb'))\n",
    "embedding_matrix = np.load(open('word_embedding_matrix.npy', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X = np.stack((q1_data, q2_data), axis=1)\n",
    "target = labels\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, target, test_size=0.25, random_state=126, stratify=target)\n",
    "Q1_train = X_train[:,0]\n",
    "Q2_train = X_train[:,1]\n",
    "Q1_val = X_val[:,0]\n",
    "Q2_val = X_val[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set up model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vec_distance(vects):\n",
    "    x, y = vects\n",
    "    return B.sum(B.square(x - y), axis=1, keepdims=True)\n",
    "#don't use squar root of the sum, it doens't give a good range to feed to the dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vec_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "nb_words=95602+1\n",
    "max_sentence_len=25\n",
    "embedding_layer = Embedding(nb_words,300,\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=max_sentence_len,trainable=False)\n",
    "#dont train this layer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ami/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:18: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=[<tf.Tenso...)`\n"
     ]
    }
   ],
   "source": [
    "lstm_layer =LSTM(128)\n",
    "\n",
    "sequence_1_input = Input(shape=(max_sentence_len,), dtype='int32')\n",
    "embedded_sequences_1 = embedding_layer(sequence_1_input)\n",
    "x1 = lstm_layer(embedded_sequences_1)\n",
    "\n",
    "sequence_2_input = Input(shape=(max_sentence_len,), dtype='int32')\n",
    "embedded_sequences_2 = embedding_layer(sequence_2_input)\n",
    "y1 = lstm_layer(embedded_sequences_2)\n",
    "\n",
    "distance=Lambda(vec_distance, output_shape=vec_output_shape)([x1, y1])\n",
    "dense1=Dense(16, activation='sigmoid')(distance)\n",
    "dense1 = Dropout(0.3)(dense1)\n",
    "\n",
    "bn2 = BatchNormalization()(dense1)\n",
    "prediction=Dense(1, activation='sigmoid')(bn2)\n",
    "\n",
    "model = Model(input=[sequence_1_input, sequence_2_input], output=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_3 (InputLayer)             (None, 25)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_4 (InputLayer)             (None, 25)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)          (None, 25, 300)       28680900    input_3[0][0]                    \n",
      "                                                                   input_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                    (None, 128)           219648      embedding_2[0][0]                \n",
      "                                                                   embedding_2[1][0]                \n",
      "____________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)                (None, 1)             0           lstm_2[0][0]                     \n",
      "                                                                   lstm_2[1][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 16)            32          lambda_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 16)            0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 16)            64          dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 1)             17          batch_normalization_2[0][0]      \n",
      "====================================================================================================\n",
      "Total params: 28,900,661\n",
      "Trainable params: 219,729\n",
      "Non-trainable params: 28,680,932\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#according to Keras, RMSprop (adaptive LR) is good for recurrent neural net. \n",
    "# Adam is another method that computes adaptive learning rates for each parameter. \n",
    "#In addition to storing an exponentially decaying average of past squared gradients vtvt like Adadelta and RMSprop, Adam also keeps an exponentially decaying average of past gradients mtmt,\n",
    "\n",
    "###RMSprop as well divides the learning rate by an exponentially decaying average of squared gradients. \n",
    "##Adam is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, \n",
    "#and is well suited for problems that are large in terms of data and/or parameter\n",
    "model.compile(loss='binary_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "early_stopping =EarlyStopping(monitor='val_loss', patience=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#optional: try calculating class weights\n",
    "#source: stack exchange, J.Guillaumin\n",
    "\n",
    "import math\n",
    "\n",
    "# labels_dict : {ind_label: count_label}\n",
    "# mu : parameter to tune \n",
    "\n",
    "def create_class_weight(labels_dict,mu=2):\n",
    "    total = np.sum(labels_dict.values())\n",
    "    keys = labels_dict.keys()\n",
    "    class_weight = dict()\n",
    "\n",
    "    for key in keys:\n",
    "        score = math.log(mu*total/float(labels_dict[key]))\n",
    "        class_weight[key] = score if score > 1.0 else 1.0\n",
    "\n",
    "    return class_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.1575228972468952, 1: 1.683427250535681}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####optional, assign weights to the labels due to imbalanced labels (0,1)\n",
    "unique, counts = np.unique(target, return_counts=True)\n",
    "labels_dict=dict(zip(unique, counts))\n",
    "\n",
    "target_weight=create_class_weight(labels_dict)\n",
    "target_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 257726 samples, validate on 85909 samples\n",
      "Epoch 1/10\n",
      "257726/257726 [==============================] - 897s - loss: 0.5562 - acc: 0.7138 - val_loss: 0.4447 - val_acc: 0.7960\n",
      "Epoch 2/10\n",
      "257726/257726 [==============================] - 895s - loss: 0.4392 - acc: 0.7978 - val_loss: 0.4135 - val_acc: 0.8107\n",
      "Epoch 3/10\n",
      "257726/257726 [==============================] - 897s - loss: 0.3973 - acc: 0.8248 - val_loss: 0.3909 - val_acc: 0.8243\n",
      "Epoch 4/10\n",
      "257726/257726 [==============================] - 898s - loss: 0.3663 - acc: 0.8429 - val_loss: 0.3805 - val_acc: 0.8304\n",
      "Epoch 5/10\n",
      "257726/257726 [==============================] - 898s - loss: 0.3412 - acc: 0.8571 - val_loss: 0.3787 - val_acc: 0.8349\n",
      "Epoch 6/10\n",
      "257726/257726 [==============================] - 897s - loss: 0.3188 - acc: 0.8694 - val_loss: 0.3734 - val_acc: 0.8377\n",
      "Epoch 7/10\n",
      "257726/257726 [==============================] - 898s - loss: 0.2990 - acc: 0.8792 - val_loss: 0.3753 - val_acc: 0.8370\n",
      "Epoch 8/10\n",
      "257726/257726 [==============================] - 897s - loss: 0.2804 - acc: 0.8894 - val_loss: 0.3800 - val_acc: 0.8348\n",
      "Epoch 9/10\n",
      "257726/257726 [==============================] - 897s - loss: 0.2627 - acc: 0.8988 - val_loss: 0.3878 - val_acc: 0.8436\n",
      "Epoch 10/10\n",
      "257726/257726 [==============================] - 896s - loss: 0.2477 - acc: 0.9057 - val_loss: 0.3943 - val_acc: 0.8416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ami/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "hist=model.fit([Q1_train, Q2_train], y_train, validation_data=([Q1_val, Q2_val], y_val), verbose=1, \n",
    "          nb_epoch=10, batch_size=256, shuffle=True,class_weight=None, callbacks=[early_stopping])\n",
    "#takes long time to initiate\n",
    "#using dense() layer and sigmoid activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model and model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# export model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"brnn_model_distance_128_d16_d05.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"brnn_model_distance_128_d16_d05.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "#json_file = open('brnn_model_distance_128_d16_d05.json', 'r')\n",
    "#loaded_model_json = json_file.read()\n",
    "#json_file.close()\n",
    "#model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "#model.load_weights(\"brnn_model_distance_128_d16_d05.h5\")\n",
    "#print(\"Loaded model from disk\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test1_data = np.load(open('test1.npy', 'rb'))\n",
    "test2_data = np.load(open('test2.npy', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60640/60643 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "pred=model.predict([test1_data, test2_data],verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  8.73683544e-04]\n",
      " [  5.60724795e-01]\n",
      " [  7.94184627e-04]\n",
      " ..., \n",
      " [  6.32060096e-02]\n",
      " [  7.53800210e-04]\n",
      " [  9.24243748e-01]]\n"
     ]
    }
   ],
   "source": [
    "submission=pd.read_csv('sample.csv')\n",
    "print pred.clip(1e-5, 0.99999)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "submission['is_duplicate']=pred.clip(1e-5, 0.99999)\n",
    "submission.to_csv('lstm_submission(13).csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with zipfile.ZipFile('lstm_submission(13).zip', 'w') as myzip:\n",
    "#    myzip.write('lstm_submission(13).csv')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
